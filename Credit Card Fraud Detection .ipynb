{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f6ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4875d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "fraud_df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99b4653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape :- \n",
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset Shape :- \\n{fraud_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bedc65a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns or Feature names :- \n",
      " Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Columns or Feature names :- \\n {fraud_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6efa9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of target variable :- \n",
      " [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique values of target variable :- \\n {fraud_df['Class'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1326283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples under each target value :- \n",
      " 0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples under each target value :- \\n {fraud_df['Class'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bfcd079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of feature names after removing Time column :- \n",
      "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
      "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# making sure which features are useful & which are not\n",
    "# we can remove irrelevant features\n",
    "fraud_df = fraud_df.drop(['Time'], axis=1)\n",
    "print(f\"list of feature names after removing Time column :- \\n{fraud_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52dbb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   V1      284807 non-null  float64\n",
      " 1   V2      284807 non-null  float64\n",
      " 2   V3      284807 non-null  float64\n",
      " 3   V4      284807 non-null  float64\n",
      " 4   V5      284807 non-null  float64\n",
      " 5   V6      284807 non-null  float64\n",
      " 6   V7      284807 non-null  float64\n",
      " 7   V8      284807 non-null  float64\n",
      " 8   V9      284807 non-null  float64\n",
      " 9   V10     284807 non-null  float64\n",
      " 10  V11     284807 non-null  float64\n",
      " 11  V12     284807 non-null  float64\n",
      " 12  V13     284807 non-null  float64\n",
      " 13  V14     284807 non-null  float64\n",
      " 14  V15     284807 non-null  float64\n",
      " 15  V16     284807 non-null  float64\n",
      " 16  V17     284807 non-null  float64\n",
      " 17  V18     284807 non-null  float64\n",
      " 18  V19     284807 non-null  float64\n",
      " 19  V20     284807 non-null  float64\n",
      " 20  V21     284807 non-null  float64\n",
      " 21  V22     284807 non-null  float64\n",
      " 22  V23     284807 non-null  float64\n",
      " 23  V24     284807 non-null  float64\n",
      " 24  V25     284807 non-null  float64\n",
      " 25  V26     284807 non-null  float64\n",
      " 26  V27     284807 non-null  float64\n",
      " 27  V28     284807 non-null  float64\n",
      " 28  Amount  284807 non-null  float64\n",
      " 29  Class   284807 non-null  int64  \n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 65.2 MB\n",
      "Dataset info :- \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "#checking null values\n",
    "print(f\"Dataset info :- \\n {fraud_df.info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59fdcb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few values of Amount column :- \n",
      " 0    149.62\n",
      "1      2.69\n",
      "2    378.66\n",
      "3    123.50\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"few values of Amount column :- \\n {fraud_df['Amount'][0:4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea55cefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few values of Amount column after applying StandardScaler:- \n",
      " 0    0.244964\n",
      "1   -0.342475\n",
      "2    1.160686\n",
      "3    0.140534\n",
      "Name: norm_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "fraud_df['norm_amount'] = StandardScaler().fit_transform(\n",
    "fraud_df['Amount'].values.reshape(-1,1))\n",
    "fraud_df = fraud_df.drop(['Amount'], axis=1)\n",
    "print(f\"few values of Amount column after applying StandardScaler:- \\n {fraud_df['norm_amount'][0:4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee609099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and target creation\n",
    "X = fraud_df.drop(['Class'], axis=1)\n",
    "y = fraud_df[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c3f08a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 29)\n",
      "(85443, 29)\n",
      "(199364, 1)\n",
      "(85443, 1)\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce14dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.999204147794436\n",
      "Confusion Matrix :- \n",
      " [[85263    33]\n",
      " [   35   112]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.77      0.76      0.77       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.89      0.88      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Building Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
    "    # initialize object for DecisionTreeClassifier class\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    # train model by using fit method\n",
    "    print(\"Model training starts........\")\n",
    "    dt_classifier.fit(X_train, y_train.values.ravel())\n",
    "    print(\"Model training completed\")\n",
    "    acc_score = dt_classifier.score(X_test, y_test)\n",
    "    print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "    # predict result using test dataset\n",
    "    y_pred = dt_classifier.predict(X_test)\n",
    "    # confusion matrix\n",
    "    print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "    # classification report for f1-score\n",
    "    print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "\n",
    "# calling decision_tree_classification method to train and evaluate model\n",
    "decision_tree_classification(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n"
     ]
    }
   ],
   "source": [
    "#Model using Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "     # initialize object for DecisionTreeClassifier class\n",
    "     rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    "     # train model by using fit method\n",
    "     print(\"Model training starts........\")\n",
    "     rf_classifier.fit(X_train, y_train.values.ravel())\n",
    "     acc_score = rf_classifier.score(X_test, y_test)\n",
    "     print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "     # predict result using test dataset\n",
    "     y_pred = rf_classifier.predict(X_test)\n",
    "     # confusion matrix\n",
    "     print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "     # classification report for f1-score\n",
    "     print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "# calling random_forest_classifier\n",
    "random_forest_classifier(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd7b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
